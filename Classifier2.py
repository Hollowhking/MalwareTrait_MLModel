import pandas as pd
import numpy as np

import torch
from torch.utils.data import Dataset, DataLoader, random_split
import tqdm
import sys
import torch.nn as nn
import matplotlib.pyplot as plt

import lightning as pl
import torch.nn.functional as F
import lightning.pytorch
from lightning.pytorch import Trainer
from sklearn.preprocessing import LabelEncoder, StandardScaler
from lightning.pytorch.loggers import CSVLogger
from torchmetrics import Accuracy

# Custom Dataset
class CustomDataset(Dataset):
    def __init__(self, X, y):
        self.X = torch.tensor(X, dtype=torch.float32)
        self.y = torch.tensor(y, dtype=torch.long)
    
    def __len__(self):
        return len(self.X)
    
    def __getitem__(self, idx):
        return self.X[idx], self.y[idx]

# Enhanced Model
class EnhancedNeuralNet(pl.LightningModule):
    def __init__(self, input_size, hid_size1, hid_size2, num_classes):
        super(EnhancedNeuralNet, self).__init__()
        self.l1 = nn.Linear(input_size, hid_size1)
        self.relu = nn.ReLU()
        self.l2 = nn.Linear(hid_size1, hid_size2)
        self.dropout = nn.Dropout(0.5)
        self.l3 = nn.Linear(hid_size2, num_classes)
        self.accuracy = Accuracy(task='multiclass', num_classes=num_classes)

    def forward(self, x):
        x = self.relu(self.l1(x))
        x = self.dropout(x)
        x = self.relu(self.l2(x))
        x = self.l3(x)
        return x
    
    def training_step(self, batch, batch_idx):
        features, target = batch
        outputs = self(features)
        loss = F.cross_entropy(outputs, target)
        self.accuracy(outputs, target)
        self.log('acc', self.accuracy, prog_bar=True)
        self.log('loss', loss)
        return loss 

    def validation_step(self, batch, batch_idx):
        inputs, target = batch
        outputs = self.forward(inputs)
        loss = F.cross_entropy(outputs, target)
        self.accuracy(outputs, target)
        self.log('val_loss', loss, prog_bar=True)
        self.log('val_acc', self.accuracy, prog_bar=True)
    
    def configure_optimizers(self):
        return torch.optim.Adam(self.parameters(), lr=0.001)

# Load and preprocess the dataset
df = pd.read_csv("Agent_Tesla.csv")

# Drop filename column
df = df.drop(df.columns[0], axis=1)
df = df.drop(df.columns[1], axis=1)
# Separate features and target
X = df.iloc[:, 1:].copy()
Y = df.iloc[:, 0].copy()

# Encode string columns in X
label_encoders = {}
for col in X.columns:
    le = LabelEncoder()
    X[col] = le.fit_transform(X[col])
    label_encoders[col] = le

# Encode target variable Y if it's not already encoded
target_encoder = LabelEncoder()
Y = target_encoder.fit_transform(Y)

# Convert X to float
X = X.astype(float)

# Standardize features
scaler = StandardScaler()
X = scaler.fit_transform(X)

# Split data into training, validation, and test sets
train_size = int(0.7 * len(X))
val_size = int(0.2 * len(X))
test_size = len(X) - train_size - val_size
train_data, val_data, test_data = random_split(CustomDataset(X, Y), [train_size, val_size, test_size])

# Hyperparameters
input_size = X.shape[1]  # Adjust based on actual input size
hidden_size1 = 3000
hidden_size2 = 1500
num_classes = 2 # Assuming binary classification
num_epochs = 50
batchsize = 128
lr = 0.001 

# Create Trainer and logger
logging = CSVLogger('./lightning_logs/', 'lstm')
trainer = pl.Trainer(max_epochs=num_epochs, logger=logging)

# Train the model
model = EnhancedNeuralNet(input_size, hidden_size1, hidden_size2, num_classes)
trainer.fit(model, DataLoader(train_data, batch_size=batchsize, num_workers=4), DataLoader(val_data, batch_size=batchsize, num_workers=4))

# Load and display metrics
metrics = pd.read_csv('./lightning_logs/lstm/version_0/metrics.csv')
val_acc = metrics['val_acc'].dropna().reset_index(drop=True).to_frame()
val_acc.index.name = 'epochs'
val_acc.columns = ['LSTM_acc']
print(val_acc)
